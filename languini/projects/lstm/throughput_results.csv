batch_size,vocab_size,config_name,seq_len,n_layers,h_dim,mlp_dim,head_dim,n_heads,compile,class,config,performance test,number of parameters,number of non-embedding parameters,device,model memory usage megabytes,step memory usage in megabytes,tokens per batch,avg step duration in ms,std step duration in ms,avg iterations per second,std iterations per second,tokens per second,OOM,flops,macs,params
1,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,804.650390625,1345.86865234375,512,513.0922783745659,12.66859240999843,1.9489671588274875,0.0475408030802847,998,False,100.07 G,49.93 GMACs,110.22 M
8,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz8_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,804.650390625,1504.18505859375,4096,546.6185031467014,12.065787818709396,1.8294294727370766,0.03979035781717782,7493,False
16,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz16_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,804.650390625,1667.27880859375,8192,748.2919311523438,8.795723494693307,1.3363768315128488,0.01534989802403702,10948,False
17,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 17, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz17.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz17_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,804.650390625,1660.59521484375,8704,781.1245998806423,9.86901112035412,1.2802054885389633,0.016061594974690174,11143,False
18,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 17, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz17.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz17_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
20,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 17, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz17.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz17_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
24,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 17, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmppk9ydu4o/throughput_results_bsz17.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz17_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,110221824,97638912,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,347.62255859375,512,164.83113437228732,2.4209060979980905,6.066815009240922,0.08970906672922854,3106,False,19.36 G,9.66 GMACs,27.29 M
8,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz8_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,362.77490234375,4096,157.14833238389758,1.6522673226691484,6.3634146467243475,0.06710754423321963,26065,False,154.86 G,77.31 GMACs,27.29 M
16,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz16_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,379.86865234375,8192,163.0372806125217,1.4845746459915286,6.133566483954207,0.055640615077882094,50246,False,309.71 G,154.62 GMACs,27.29 M
24,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz24_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,396.46240234375,12288,201.29561869303384,1.2688136908033179,4.967818010609322,0.031306154581775526,61045,False,464.57 G,231.93 GMACs,27.29 M
32,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz32_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,413.30615234375,16384,232.6614023844401,1.0149543101735743,4.2980915173357435,0.018802459477919947,70420,False,619.42 G,309.24 GMACs,27.29 M
40,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz40_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,430.96240234375,20480,261.35855272081164,5.809854818444551,3.8261613771186576,0.08186433817828886,78360,False,774.28 G,386.55 GMACs,27.29 M
48,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz48_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,444.74365234375,24576,289.5541720920139,8.506029415273419,3.453585188481491,0.09576060767977153,84875,False
56,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz56_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,462.71240234375,28672,317.57115342881946,0.6348122054902539,3.1489006139348246,0.006300003196805298,90285,False
64,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz64.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz64_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,478.30615234375,32768,354.2480197482639,4.9109013589735095,2.822880988045102,0.03801880617946271,92500,False
72,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz72.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz72_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,495.525390625,36864,394.26819186740454,0.4879261188638634,2.5363446015353626,0.0031393336612315793,93500,False
80,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 80, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz80.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz80_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,510.869140625,40960,432.74833509657117,2.0632369060345557,2.3108118943469584,0.010906747602647027,94651,False
82,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 82, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz82.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz82_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,232.15625,518.392578125,41984,442.95731947157117,0.649193325007605,2.2575538455780717,0.0033077625935289405,94781,False
83,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 82, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz82.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz82_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
84,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 82, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz82.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz82_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
88,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 82, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcwj7nj0i/throughput_results_bsz82.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz82_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,27287552,18898944,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,668.82568359375,512,309.2464023166233,15.44550606687217,3.233667368508771,0.15156537979014753,1656,False,41.92 G,20.94 GMACs,53.52 M
8,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz8_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,720.03271484375,4096,300.8954908582899,3.064566796538221,3.323413046661311,0.03407192647151668,13613,False,335.38 G,167.5 GMACs,53.52 M
16,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz16_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,772.93896484375,8192,368.90194023980035,3.8612852640821798,2.7107474667928333,0.027843264938083718,22206,False,670.75 G,335.01 GMACs,53.52 M
24,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz24_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,808.86083984375,12288,457.4641587999132,5.78938470293073,2.185963601221451,0.02727999432400463,26861,False,1006.13 G,502.51 GMACs,53.52 M
32,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz32_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,865.36083984375,16384,534.2408786349827,0.7687474803568344,1.8718148310834237,0.0026932867733980162,30668,False
40,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz40_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,917.61865234375,20480,627.6136881510416,9.041910359994223,1.5933368230798366,0.022429566132609654,32632,False
48,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz48_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,968.56396484375,24576,709.592759874132,13.702292324705608,1.4092590236932248,0.02601349242801925,34634,False
56,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz56_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,1020.14208984375,28672,787.7173055013021,1.3235025203755535,1.2694909620699542,0.0021311539910281252,36399,False
60,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 60, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz60.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz60_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,332.220703125,1042.59521484375,30720,831.8366970486111,1.1240032642803535,1.2021590337959829,0.0016237287339313739,36930,False
61,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 60, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz60.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz60_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
62,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 60, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz60.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz60_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
64,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 60, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'block_length': 8, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmphytbcj9c/throughput_results_bsz60.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl8_books16384_bsz60_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,53518848,40935936,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpse8p3si1/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16_fast_coupled'})",forward and backward,730291200,705125376,NVIDIA GeForce RTX 3090,3554.21484375,8613.25927734375,512,1047.6853162977432,15.107707641639172,0.9544850771925953,0.01363591125920257,489,False,722.39 G,360.78 GMACs,730.29 M
2,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpse8p3si1/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz2_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,730291200,705125376,NVIDIA GeForce RTX 3090,3554.21484375,8695.34130859375,1024,1018.1454535590278,7.0848188547381525,0.9821779358778271,0.006801260635221097,1006,False
3,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpse8p3si1/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz2_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,730291200,705125376,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
5,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpse8p3si1/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz2_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,730291200,705125376,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
8,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmpse8p3si1/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz2_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,730291200,705125376,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,831.685546875,1448.91552734375,512,956.760498046875,65.89008988306391,1.0451936530003003,0.0690740937231079,535,False,107.32 G,53.55 GMACs,117.31 M
8,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz8_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,831.685546875,1725.72412109375,4096,959.120383126395,24.229953775415392,1.042621987388436,0.02609015055310968,4271,False,858.52 G,428.42 GMACs,117.31 M
16,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz16_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,831.685546875,2043.45068359375,8192,1083.9315447126116,29.55609121400613,0.9225674858140005,0.02506096324550374,7558,False
20,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz20_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz20.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 20,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,831.685546875,2184.30224609375,10240,1189.5899222237724,17.827906591220202,0.8406258167778015,0.012596619507801905,8608,False
22,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz22_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz22.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 22,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,831.685546875,2227.75537109375,11264,1243.3077741350446,9.313526509412773,0.8043060783527143,0.006018551368481647,9060,False
23,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz22_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz22.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 22,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
24,16384,small,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz22_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpe93mt7x_/throughput_results_bsz22.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 22,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,117308928,104726016,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpbeziynru/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,786951168,761785344,Tesla V100-SXM2-32GB-LS,3770.35546875,9343.64208984375,512,2034.9115426199776,52.988004307208364,0.4914218525255824,0.012671051871474262,252,False,780.37 G,389.77 GMACs,786.95 M
3,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz3_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpbeziynru/throughput_results_bsz3.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 3,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,786951168,761785344,Tesla V100-SXM2-32GB-LS,3770.35546875,9617.89990234375,1536,1986.9483991350446,62.10503386281642,0.5032843331187254,0.015568379570535631,773,False
4,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz3_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpbeziynru/throughput_results_bsz3.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 3,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,786951168,761785344,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
5,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz3_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpbeziynru/throughput_results_bsz3.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 3,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,786951168,761785344,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
8,16384,large,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz3_micro1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpbeziynru/throughput_results_bsz3.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 3,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,786951168,761785344,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpefm6ri82/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,361056256,344279040,Tesla V100-SXM2-32GB-LS,2145.6953125,4335.95068359375,512,1931.5689435686384,23.474084319197484,0.5177138529430207,0.0061696345919895375,265,False,352.74 G,176.09 GMACs,361.06 M
5,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz5_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpefm6ri82/throughput_results_bsz5.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 5,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,361056256,344279040,Tesla V100-SXM2-32GB-LS,2145.6953125,4799.84130859375,2560,1941.8276541573662,68.43933248850215,0.5149787613020367,0.01810833216458791,1318,False
7,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz7_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpefm6ri82/throughput_results_bsz7.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 7,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,361056256,344279040,Tesla V100-SXM2-32GB-LS,2145.6953125,4934.66162109375,3584,1857.8652169363838,58.543789976536566,0.5382521782979489,0.016324812002499696,1929,False
8,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz7_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpefm6ri82/throughput_results_bsz7.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 7,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,361056256,344279040,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,700.85693359375,512,590.2272382463727,11.24959190635754,1.6942627096829779,0.03202791543411506,867,False,44.34 G,22.15 GMACs,55.88 M
8,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz8_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,792.29833984375,4096,550.9923836844308,30.054705572211212,1.8149071196104387,0.09131372350652273,7434,False,354.7 G,177.17 GMACs,55.88 M
16,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz16_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,897.70458984375,8192,609.3554600306919,8.268358246885674,1.6410782631694678,0.02289548426128635,13444,False,709.41 G,354.33 GMACs,55.88 M
24,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz24_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,980.81396484375,12288,647.5969369070871,15.267945385638603,1.5441703674140037,0.035193735794450155,18975,False,1064.11 G,531.5 GMACs,55.88 M
32,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz32_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1087.50146484375,16384,739.7925458635602,40.8507053845374,1.3517303000568888,0.06987896007087309,22147,False,1418.81 G,708.67 GMACs,55.88 M
40,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz40_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1185.22021484375,20480,799.3955644880023,15.889661324016599,1.2509451445861863,0.024938429718876633,25619,False
48,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz48_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz48.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 48,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1285.82958984375,24576,900.5376281738281,13.394937075715193,1.1104477688820937,0.01655870419010278,27290,False
56,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz56_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1384.65771484375,28672,991.9956883021763,12.184696961254344,1.0080688976698309,0.012574852352849799,28903,False
64,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz64_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz64.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 64,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1472.25146484375,32768,1053.9919956752233,21.172944839491873,0.9487738086278026,0.019254314277740284,31089,False
72,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz72_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz72.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 72,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1563.291015625,36864,1136.290780203683,21.020492669378815,0.8800564234277669,0.016299941630142464,32442,False
80,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz80_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz80.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 80,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1658.408203125,40960,1247.6910574776787,20.327842763266215,0.8014804578479477,0.013218362214500854,32829,False
84,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz84_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz84.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 84,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1716.736328125,43008,1282.5528651646205,36.82036321920055,0.7796949561776124,0.021254301101297335,33533,False
85,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz85_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz85.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 85,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,341.232421875,1718.30322265625,43520,1305.985116141183,16.432185358669724,0.7657055104538385,0.009575334941819913,33324,False
86,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz85_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz85.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 85,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
88,16384,tiny,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 8,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl8_books16384_bsz85_micro1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmp_5bp8gju/throughput_results_bsz85.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 85,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,55881216,43298304,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,355.61474609375,512,299.38936941964283,6.858736738023592,3.340131955715293,0.07601558231942304,1710,False,19.89 G,9.93 GMACs,27.81 M
8,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz8_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,386.01708984375,4096,312.2513187953404,12.38797897114295,3.2025485235994546,0.12423469930155252,13118,False,159.15 G,79.46 GMACs,27.81 M
16,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz16_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,418.11083984375,8192,314.745125906808,5.566808449697073,3.1771739025947205,0.05620036692921015,26027,False,318.3 G,158.91 GMACs,27.81 M
24,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz24_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,450.45458984375,12288,313.0567648751395,15.425349347612862,3.194308867271541,0.14702631564407984,39252,False,477.45 G,238.37 GMACs,27.81 M
32,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz32_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,484.54833984375,16384,330.2565482003348,5.062868902986538,3.0279490458229956,0.04582791738497428,49610,False,636.6 G,317.83 GMACs,27.81 M
40,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz40_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,514.89208984375,20480,360.83450099400113,4.918873808402608,2.7713536184740413,0.03814426167250565,56757,False,795.75 G,397.28 GMACs,27.81 M
48,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz48_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz48.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 48,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,547.11083984375,24576,402.36339678083147,10.563030579721804,2.4853155331738663,0.06159065828201415,61079,False,954.9 G,476.74 GMACs,27.81 M
56,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz56_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,581.39208984375,28672,428.1422119140625,4.519946677194896,2.3356725222896775,0.02455089782101385,66968,False,1114.06 G,556.2 GMACs,27.81 M
64,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz64_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz64.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 64,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,612.79833984375,32768,469.36841474260603,6.75894537232809,2.130522567327807,0.03053883505906535,69813,False
72,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz72_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz72.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 72,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,644.642578125,36864,494.4013410295759,3.973678187505369,2.022648235373978,0.016236581533170365,74563,False
80,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz80_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz80.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 80,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,676.861328125,40960,577.8090253557477,17.05239705016661,1.7306756317700578,0.04723481598339368,70888,False
88,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz88_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz88.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 88,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,709.580078125,45056,557.3577008928571,5.949179575769135,1.7941799286132651,0.01880036220970173,80839,False
96,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz96_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz96.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 96,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,741.923828125,49152,608.0819353376116,5.310223078528904,1.6445152238321181,0.01434749093078114,80831,False
104,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz104_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz104.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 104,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,774.455078125,53248,652.6187482561384,6.142617878544354,1.532288189194838,0.01434468638101089,81591,False
112,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz112_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz112.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 112,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,234.16015625,806.986328125,57344,696.6116594587054,7.177183085428933,1.43552004394678,0.014709920355732925,82318,False
113,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz112_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz112.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 112,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
114,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz112_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz112.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 112,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
116,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz112_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz112.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 112,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
120,16384,mini,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'block_length': 16,
 'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 1000,
 'exp_name': 'quasiLSTM_bl16_books16384_bsz112_micro1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'is_quasi': True,
 'log_activations_every': -1,
 'log_ckpt_every': 5000,
 'log_grads_every': 1000,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 512,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/lstm',
 'results_pickle_file': '/tmp/tmpp688yk_p/throughput_results_bsz112.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 112,
 'vocab_size': 16384,
 'wandb_project_name': 'lstm'}",forward and backward,27812864,19424256,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmp7a6o0z7i/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz1_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,361056256,344279040,NVIDIA GeForce RTX 3090,2145.6953125,4336.06787109375,512,978.9521552191841,6.719205314984941,1.0215003814727834,0.007010770459034417,523,False,352.74 G,176.09 GMACs,361.06 M
5,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmp7a6o0z7i/throughput_results_bsz5.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz5_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,361056256,344279040,NVIDIA GeForce RTX 3090,2145.6953125,4799.95849609375,2560,1020.2472127278646,9.280159511752457,0.980154601281655,0.008847088768053093,2509,False
6,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmp7a6o0z7i/throughput_results_bsz5.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz5_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,361056256,344279040,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
7,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmp7a6o0z7i/throughput_results_bsz5.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz5_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,361056256,344279040,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
8,16384,medium,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 512, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'lstm', 'is_quasi': True, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'block_length': 16, 'project_path': '/home/imanol/Languini/languini/projects/lstm', 'compile': 'default', 'results_pickle_file': '/tmp/tmp7a6o0z7i/throughput_results_bsz5.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'quasiLSTM_bl16_books16384_bsz5_micro1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,361056256,344279040,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
